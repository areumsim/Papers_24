# Papers (2024)

</br>

## Paper List (2024)
|                                                   Title                                                  	| Journal / Coference  	| Year 	|                                                                                                                                                                   About                                                                                                                                                                  	|             Labels/Tag             	| Read / Review 	|
|:--------------------------------------------------------------------------------	|:--------	|:----	|:---------------------------------	|:----	|:----	|
| [SegGPT] SegGPT: Segmenting Everything In Context | CVPR  | 2023 	|<sup> - 여러 Segmantation Task들의 output을 동일한 format으로 맞춰서  ‘In-contenxt learning framework’로<br>- Painter 구조 기반으로 이미지에 Semantic 정보를 학습, Segmantation 모델<br>- GPT랑 관련 X </sup> |    |   |
| [Painter] Images Speak in Images: A Generalist Painter for In-Context Visual Learning | CVPR  | 2023  |<sup> - In-Context learning 모델<br>- output을 Image로 재정의하여 general purpose task 정의 </sup>	| <sup> </sup>|   |
| [ImageBind] ImageBind: One Embedding Space To Bind Them All   | CVPR  | 2023 	|<sup> - 6가지 다른 양식에 걸쳐 joint 임베딩을 학습하는 방식 : 이미지의 binding 속성은 각 양식의 임베딩(소리, 질감, 바람 , … 총 6개)을 이미지 임베딩에 정렬하는 것만으로 모든 양식에 걸쳐 정렬이 가능<br><br>- 훈련시 모든 pari data가 필요 x , image-pari data로 구분  : 여러 유형의 image-paired 데이터를 활용하여 단일 공유 표현 공간을 학습 	|<sup>   </sup>|   |
| [Paged Attention, vLLM] Efficient Memory Management for Large Language Model Serving with PagedAttention 	| SOSP  | 2023 	|<sup> - operating system에 사용되는 paging, virtual memory를 이용한 paged attention 제안<br>- LLM Inference 성능 향상  </sup>| <sup> `LLM Serving`, `PagedAttention` </sup> |   |
| [SAG Rec] Self-Attentive Sequential Recommendation    | ICDM                 	| 2018 	|<sup> - 사용자 세션 정보를 바탕으로 아이템 추천<br>- Self-Attention 도입<br>- 각 아이템의 임베딩 벡터를 생성하는 과정에서 셀프 어텐션 사용 ( 세셧 내에서 시간적 순서를 고려 )  </sup>  |<sup> `RS` </sup>    |   |
| [FaceNet] FaceNet: A Unified Embedding for Face Recognition and Clustering    | CVPR  | 2015  |<sup> - 이미지를 직접적으로 embedding vector(e.v)로 mapping → output 형태가 e.v 이기 때문에 직접 optimize 가능, 차원이 감소<br>- 훈련 시킬 때 triplet loss 사용<br>- contrastive learning 초기 논문 </sup>| <sup> `triplet loss`, `contrastive learning` </sup> |   |
| [VQ-GAN] Taming Transformers for High-Resolution Image Synthesis  | IEEE/CVF  | 2021  | <sup> </sup> |   |  |
| [CRAG] Corrective Retrieval Augmented Generation  |   | 2024  | <sup> (Plug & Plug 로 기존 RAG 시스템을 개선하고자 웹 검색 기능을 결합해서 관련 없는 정보를 필터링하고 분해 후 재조합하는 방법론) </sup>| <sup> `CRAG`, `RAG` </sup> |   |   
| [ConvNext] A ConvNet for the 2020s    | FAIR <br>(facebook)   | 2022 	| <sup> - convnet 확장 (ViT를 능가하는 성능 .. )<br>- CNN에 Transformer 구조 및 최신 기법들을 적용  </sup>  |   |   |   
| The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits | -  | 2024 	| <sup>   </sup> | <sup> </sup> |   |
| Denoising Self-Attentive Sequential Recommendation    | Recsys    | 2022 	|<sup>   </sup> | <sup> </sup> |   |
|   |   |   | <sup>   </sup>| <sup> </sup> |   |

</br>
</br>

### etc
|                         Title                        	|      	|                             	|   	|   	|   	|
|:----------------------------------------------------	|:----	|:---------------------------	|:-	|:-	|:- |
| [정리] Generative AI 발전 : GPT와 Diffusion 중심으로 	|      	| https://xoft.tistory.com/70 	|   	|   	|   	|
| [논문 정리] NeRF 개선 방향 및 기술 동향              	| NeRF 	| https://xoft.tistory.com/5  	|   	|   	|   	|
|                                                      	|      	|                             	|   	|   	|   	|
|                                                      	|      	|                             	|   	|   	|   	|

</br>
</br>


### 참고 paper ( ~2023)

| Title | Journal/Coference  | Year | About | Labels/Tag | Url | Github/Code | Read/Review Done |
| --- | --- | --- | --- | --- | --- | --- | --- |
| CLIP |  |  |  |  |  |  |  |
| GLIDE |  |  |  |  |  |  |  |
| DINO |  |  |  |  |  |  |  |
|  |  |  |  |  |  |  |  |
|  |  |  |  |  |  |  |  |


</br>
</br>
</br>
</br>

## Paper Review Format

### **Review Rormat**

**Title** :  

**Journal/Coference** :   

**Year :**   

**About** : 

**Label / Tag** :  

**Url** :

**Github** : 
